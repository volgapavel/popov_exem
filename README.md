# Breastâ€‘Cancer Diagnostic MLÂ Pipeline

*Automated with ApacheÂ Airflow â€” Course project, MPTI University (2025)*

---

## ğŸ“‹ TableÂ ofÂ Contents

1. [Problem Statement](#1-Â·-problem-statement)
2. [Solution Overview &Â Architecture](#2-Â·-solution-overview--architecture)
3. [Repository Layout](#3-Â·-repository-layout)
4. [ETL / ML PipelineÂ Steps](#4-Â·-etl--ml-pipeline-steps)
5. [Airflow DAG](#5-Â·-airflow-dag)
6. [Storage &Â Export of Artefacts](#6-Â·-storage--export-of-artefacts)
7. [Operational Reliability &Â Error Handling](#7-Â·-operational-reliability--error-handling)
8. [How toÂ RunÂ Locally](#8-Â·-how-to-run-locally)
9. [DesignÂ Choices](#9-Â·-design-choices)
10. [NextÂ Steps](#10-Â·-next-steps)
11. [Screenshots](#11-Â·-screenshots)

---

## 1Â Â· Problem Statement

Early identification of malignant breast tumours saves lives, yet manual evaluation of biopsy imagery is slow and errorâ€‘prone.  Using the public **BreastÂ CancerÂ WisconsinÂ (Diagnostic)** dataset (569 observations, 30 numeric features) we tackle a **binary classification** task:

> **Goal**â€ƒPredict whether a tumour is **malignantÂ (M)** or **benignÂ (B)** given morphometric cellâ€‘nuclei measurements.

The focus is not stateâ€‘ofâ€‘theâ€‘art accuracy but **reproducible automation** of the full ML lifecycle.

---

## 2Â Â· Solution Overview &Â Architecture

```mermaid
flowchart TD
    subgraph ETL\u00A0Pipeline (Airflow DAG)
        A[LoadÂ Data] --> B[Preâ€‘process]
        B --> C[TrainÂ Model]
        C --> D[EvaluateÂ Metrics]
        D --> E[ExportÂ Results]
    end
```

* **Orchestrator** â€“ ApacheÂ Airflow (`ml_pipeline_breast_cancer` DAG).
* **Processing** â€“ plain Python scripts in `etl/`, each fully runnable both via Airflow and CLI.
* **Storage** â€“ by default local folder `results/`; optional S3 export via `boto3`.

---

## 3Â Â· Repository Layout

```
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ ml_pipeline_dag.py      # Airflow DAG definition
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ load_data.py            # stepÂ 1
â”‚   â”œâ”€â”€ preprocess_data.py      # stepÂ 2
â”‚   â”œâ”€â”€ train_model.py          # stepÂ 3
â”‚   â”œâ”€â”€ evaluate_metrics.py     # stepÂ 4
â”‚   â””â”€â”€ export_results.py       # stepÂ 5 (copy / S3 upload)
â”œâ”€â”€ results/                    # artefacts live here (gitâ€‘ignored)
â”œâ”€â”€ config.yaml                 # overridable parameters
â”œâ”€â”€ requirements.txt            # pinned deps incl. Airflow
â””â”€â”€ README.md                   # **you are here**
```

---

## 4Â Â· ETL / ML PipelineÂ Steps

| Â StepÂ                | Python entryâ€‘point        | Description                                                                 | Key outputs                                          |
| -------------------- | ------------------------- | --------------------------------------------------------------------------- | ---------------------------------------------------- |
| 1Â Â·Â LoadÂ Data        | `etl/load_data.py`        | Fetch dataset via `sklearn.datasets` (or local `wdbc.data`); log basic EDA. | `results/data_raw.csv`                               |
| 2Â Â·Â Preâ€‘process      | `etl/preprocess_data.py`  | Drop `id`, snakeâ€‘case headers, validate schema, zâ€‘score scaling.            | `results/data_clean.csv`, `results/scaler.pkl`       |
| 3Â Â·Â TrainÂ Model      | `etl/train_model.py`      | 80/20 stratified split, train `LogisticRegression`, quick accuracy log.     | `results/model.pkl`, `results/test_data.csv`         |
| 4Â Â·Â EvaluateÂ Metrics | `etl/evaluate_metrics.py` | Accuracy, Precision, Recall, F1 on heldâ€‘out set; JSON dump.                 | `results/metrics.json`                               |
| 5Â Â·Â ExportÂ Results   | `etl/export_results.py`   | Copy model & metrics to `results/export/` **or** upload to S3.              | copied files *or* `s3://â€¦/model.pkl`, `metrics.json` |

---

## 5Â Â· Airflow DAG

* **Name** â€” `ml_pipeline_breast_cancer`
* **Schedule** â€” *manual* (`schedule_interval=None`); flip to `@daily` if needed.
* **Dependencies** â€”
  `load_data â†’ preprocess_data â†’ train_model â†’ evaluate_metrics â†’ export_results`

### Oneâ€‘off dry run (no scheduler)

```bash
# inside activated venv + envÂ vars AIRFLOW_HOME & PYTHONPATH pointing to repo
airflow tasks test ml_pipeline_breast_cancer load_data 2025-06-17
```

### Full trigger from CLI

```bash
airflow dags trigger ml_pipeline_breast_cancer
```

---

## 6Â Â· Storage &Â Export of Artefacts

### Local layout (default)

```
results/
â”œâ”€â”€ data_raw.csv
â”œâ”€â”€ data_clean.csv
â”œâ”€â”€ model.pkl
â”œâ”€â”€ metrics.json
â””â”€â”€ export/            # populated by export_results
    â”œâ”€â”€ model.pkl
    â””â”€â”€ metrics.json
```

*`results/` is listed in `.gitignore` â€” artefacts never leak to VCS.*

### S3 Integration

* Enable by calling `export_results(mode="s3", bucket="ml-artifacts", prefix="bc_demo/")` (done via `op_kwargs` in DAG).
* **Credentials** â€” AWS keys from environment variables **or** `~/.aws/credentials` (not committed).
* Upload relies on `boto3.upload_file`, therefore supports multipart and automatic retries.

---

## 7Â Â· Operational Reliability &Â Error Handling

| Failure point                                             | Possible exception(s)                                                                  | Mitigation / behaviour                                                                                         |
| --------------------------------------------------------- | -------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------- |
| **Data source unreachable** (`load_data` with remote CSV) | `URLError`, `FileNotFoundError`                                                        | Task fails â†’ DAG stops; retry once (see `default_args`). Local *sklearn* fallback is default to minimise risk. |
| **Invalid / corrupt CSV**                                 | `ParserError`, custom schema `ValueError`                                              | Schema checks in `preprocess_data` raise explicit `ValueError` (logged).                                       |
| **Missing / NaN values after cleaning**                   | `ValueError("â€¦propuskiâ€¦")`                                                             | Failâ€‘fast with clear log; nothing downstream runs.                                                             |
| **Model training diverges** (`ConvergenceWarning`)        | Caught & logged; hard failure occurs only if scikit raises an error (rare for LogReg). |                                                                                                                |
| **Disk full when writing artefacts**                      | `OSError` from `to_csv`/`joblib.dump`                                                  | Task fails; Airflow retry after 5Â min.                                                                         |
| **S3 upload issues**                                      | `EndpointConnectionError`, `ClientError`                                               | `boto3` builtâ€‘in exponential backâ€‘off; if still failing â€” task error â†’ you can reâ€‘run only `export_results`.   |

### What ifâ€¦

* **Connection lost to data source** â€” Task fails quickly; upstream files remain intact; user can relaunch when source is back.
* **Source returns invalid data** â€” Validation error surfaces in log, pipeline halts *before* modelling.
* **Model does not train** (e.g. singular input) â€” scikit raises error â†’ task fails; artefacts not produced.

Airflowâ€™s *â€œeach task is atomicâ€* principle guarantees partial outputs from failed tasks are isolated to their `results/` folder and are overwritten on the next successful run.

---

## 8Â Â· How to RunÂ Locally

```bash
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
# Airflow setup
export AIRFLOW_HOME=$(pwd)        # DB, logs & dags live here
export PYTHONPATH=$(pwd)

# initialise DB + create admin user
airflow db init
airflow users create --username admin --password admin \
                     --firstname Admin --lastname User \
                     --role Admin --email admin@example.com

# launch services (two terminals)
airflow scheduler
# second tab
airflow webserver -p 8080
```

Navigate to [http://localhost:8080](http://localhost:8080), switch **ml\_pipeline\_breast\_cancer** to *on* and trigger.

---

## 9Â Â· DesignÂ Choices

* **Vanilla Python scripts** â€” easier to unitâ€‘test & run adâ€‘hoc; no hidden Airflow hooks.
* **Single source of paths** â€” `config.yaml` / envâ€‘vars; makes Dockerisation trivial.
* **Local first** â€” Works completely offline (dataset ships with scikit). Cloud upload is optional.
* **Strict validation** â€” Fail fast on data issues â‡’ no silent degradation.

---

## 10Â Â· NextÂ Steps

* Swap LogisticRegression with GradientÂ Boosting & log ROCâ€‘AUC.
* Containerise each step; run with `DockerOperator`.
* Push artefacts to S3 + trigger downstream automated report (e.g. Streamlit).
* GitHubÂ Actions CI that fails on metric regression vs. reference run.

---

## 11Â Â· Screenshots

Screenshots of the successful DAG run are stored in `docs/img/` and referenced below:

| DAG graph                        |                       
| -------------------------------- |  
| ![graph](docs/img/dag_graph.png) | 

---

Â©Â 2025Â PavelÂ Popov â€” MPTIÂ DS Masterâ€™s coursework
